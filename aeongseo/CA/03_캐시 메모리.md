# 캐시 메모리 (Cache Memory)

## 정의
- CPU와 주기억장치(RAM) 사이에 위치한 고속 기억장치
- CPU가 자주 접근하는 데이터와 명령어를 저장하여 평균 메모리 접근 시간(AMAT, Average Memory Access Time)을 줄여줌  
- 일반적으로 **SRAM(정적 RAM)** 기반으로 구현 → DRAM보다 빠르지만 비쌈  

## 필요성
- CPU 클럭 속도는 매우 빠르지만, **DRAM(메인 메모리)의 접근 속도는 상대적으로 느림**  
- 매번 메모리에서 직접 데이터를 읽으면 **CPU 성능 저하**  
- 캐시는 **중간 완충 장치(buffer)** 역할 → CPU가 최대 속도에 가깝게 동작 가능

## 동작 원리 (지역성의 원리)
- **시간적 지역성 (Temporal Locality)**  
  최근 접근된 데이터는 가까운 미래에 다시 접근될 확률 높음  
  → 최근 사용한 명령어/데이터를 캐시에 보관  

- **공간적 지역성 (Spatial Locality)**  
  특정 주소가 참조되면 주변 주소도 곧 접근될 가능성 높음  
  → 한 블록 단위로 데이터를 캐시에 저장  

## 캐시 계층 구조 (Cache Hierarchy)
- **L1 캐시**: CPU 코어 내부, 매우 빠름, 용량 작음(수십 KB), 명령어/데이터 분리 가능  
- **L2 캐시**: L1보다 크고 느림(수백 KB~수 MB), CPU 다이에 포함  
- **L3 캐시**: 여러 코어가 공유, 대용량(수 MB~수십 MB), 메모리보다는 빠름  

## 캐시 매핑 방식
- **직접 매핑(Direct Mapping)**  
   - 메모리 블록 → 캐시 특정 줄에 배치  
   - 단순 구현, 충돌 발생 가능  

- **전 연관 매핑(Fully Associative Mapping)**  
   - 메모리 블록이 캐시 어느 줄이든 배치 가능  
   - 검색 회로 많아 복잡, 비용 높음  

-  **집합 연관 매핑(Set-Associative Mapping)**  
   - 캐시를 여러 집합(Set)으로 나누고, 각 집합 내에서 연관 매핑  
   - 성능과 구현 복잡성 균형 → 널리 사용  

## 캐시 성능 지표
- **캐시 히트(Cache Hit)**: 캐시에 데이터 존재 → 빠른 접근  
- **캐시 미스(Cache Miss)**: 데이터 없음 → 메모리 접근 후 캐시에 적재  
- **캐시 미스율(Miss Rate)**: 전체 접근 중 미스 비율  
- **평균 메모리 접근 시간(AMAT)**:  
  ```
  AMAT = Hit Time + Miss Rate × Miss Penalty
  ```
  ## 쓰기 정책 (Write Policies)
- **Write-through**  
  - 캐시와 메인 메모리에 동시에 기록  
  - 데이터 일관성 보장, 하지만 쓰기 속도 느림  

- **Write-back**  
  - 캐시에만 기록 후, 나중에 변경된 블록만 메모리에 반영 (Dirty bit 필요)  
  - 성능 우수하지만 구현 복잡  

- **Write-allocate / No-write-allocate**  
  - **Write-allocate**: 쓰기 미스 발생 시 블록을 캐시에 적재 후 기록  
  - **No-write-allocate**: 메모리에 직접 기록, 캐시는 저장하지 않음

## 캐시 일관성 (Cache Coherence)
- 멀티코어 환경에서 각 코어 캐시가 동일 메모리 데이터를 다르게 저장할 수 있음 → **일관성 문제 발생**  
- 해결 방법:  
  - **Snooping 방식**: 모든 캐시가 버스 활동을 감시하며 변경 감지  
  - **Directory 기반 방식**: 중앙 디렉토리가 각 블록 상태를 추적  
