# 캐시 메모리(Cache Memory)

## 캐시 메모리의 개념

- CPU와 RAM(주기억장치) 사이 위치한 고속 메모리

- CPU가 자주 사용하는 데이터나 명령어를 임시로 저장하여 빠르게 접근할 수 있도록 도움

## 캐시 메모리 사용 과정

- CPU의 연산 속도 >> RAM 속도 

이 속도차이를 보완하기 위해 캐시 메모리 사용

- CPU가 먼저 캐시 메모리 확인. 원하는 데이터가 존재하면 바로 사용 (캐시 히트)

- 없는 경우 RAM에서 가져와 캐시에 저장한 뒤 사용 (캐시 미스)

- 결과적으로, CPU와 RAM 간의 속도 차이를 감소시켜 전체 성능을 향상시키는 버퍼의 역할

## 캐시 메모리 사용 이유

1. CPU와 RAM 속도 불균형
    - CPU는 ns단위 동작, RAM의경우 10~100ns 단위 동작
    - CPU는 RAM의 동작을 기다리며 대기하는 시간 증가

2. 지역성(Locality) 원리
    - 프로그램 실행 시 데이터 접근 패턴은 특정 규칙 존재
    - 시간적 지역성(Temporal Locality) : 최근 사용한 데이터는 다시 사용될 가능성 높음
    - 공간적 지역성(Spatial Locatily) : 특정 데이터 근처에 있는 데이터가 함께 사용될 가능성 높음
    - 이러한 원리로 자주 사용하거나 근처에 있는 데이터를 캐시에 미리 저장

3. 전체 시스템 성능 향상
    - 캐시가 없는 경우 CPU가 RAM의 데이터를 불러올 때마다 지연 발생
    - 캐시가 있는 경우 접근 속도가 크게 향상되어 프로그램 실행 시간 단축

## 캐시 메모리 구조와 종류
1. 레벨 구조
    - L1 : CPU 내부에 존재, 가장 빠르고 작음 (10~100KB 단위)
    - L2 : CPU 내부 또는 외부에 존재, L1보다 느리고 큼 (100~1000KB 단위)
    - L3 : CPU 칩 내부 공유 캐시, 가장 크지만 가장 느림 (1~10MB 단위)

2. 캐시 매핑 방식
    - 직접 매핑(Direct Mapping)
        - 주기억장치의 특정 블록의 캐시의 딱 한 위치에만 저장될 수 있는 방식
        - 👍 구현 단순, HW 비용 적음, 검색 속도 빠름
        - 👎 서로 다른 블록이 같은 캐시 라인에 mapping되면서 충돌 발생
    - 연관 매핑(Associative Mapping)
        - 주기억장치의 블록이 캐시의 어느 위치에든 자유롭게 저장되는 방식
        - 👍 충돌 거의 없음, 캐시 최대 사용 가능
        - 👎 하드웨어 복잡도↑, 검색 속도↓
    - 집합 연관 매핑(Set-Assoociative Mapping)
        - 직접 매핑과 연관 매핑의 절충안, 캐시를 여러개의 집합으로 나누고, 각 블록은 특정 집합 안에서만 저장 가능(direct와 비슷), 집합 내부에서는 자유롭게 배치 가능(associative와 비슷)
        - 👍 충돌 가능성 감소, 하드웨어 복잡도 완화
        - 👎 직접 매핑보다 복잡, 연관 매핑보다 효율 낮음


