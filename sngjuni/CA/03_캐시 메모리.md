# 캐시 메모리

### 캐시 메모리란?

---

- CPU와 메모리 사이에 위치하는 **고속 기억 장치**
- CPU는 메모리보다 훨씬 빠르기 때문에, 메모리에 직접 접근하면 **병목(von Neumann Bottleneck)** 현상 발생
- 이를 완화하기 위해 **최근 사용한 데이터/명령어를 미리 저장**하여 CPU가 빠르게 접근할 수 있도록 함.

### 캐시 메모리의 동작 원리

---

> **지역성(Locality)** 개념을 활용
> 
- 시간 지역성(Temporal Locality)
    - 최근에 접근한 데이터는 곧 다시 사용될 가능성이 높음.
    - ex) for나 while 같은 반복문에서 사용되는 조건 변수
- 공간 지역성(Spatial Locality)
    - 특정 데이터 근처의 데이터가 곧 사용될 가능성이 높음.
    - ex) 배열 순차 접근

### 캐시 히트(Cache Hit) & 캐시 미스(Cache Miss)

---

**캐시 히트**

- CPU가 필요한 데이터를 캐시에서 바로 찾은 경우 → 빠른 속도로 데이터 접근 가능
- 성능 지표: 히트율 (Hit Ratio)

**캐시 미스**

- CPU가 찾는 데이터가 캐시에 없어, 메모리에서 다시 가져와야 하는 경우 → 접근 시간이 길어지고 성능 저하 발생
- 성능 지표: 미스율(Miss Ratio)

**캐시 미스 유형**

- 강제 미스(Compulsory Miss, Cold Miss)
    - 처음 접근하는 데이터는 캐시에 없으므로 무조건 발생
    - 해결방법 : 프리패칭(prefetching)
- 용량 미스(Capacity Miss)
    - 캐시 크기가 부족해서 전체 작업 집합(Working Set)을 담을 수 없는 경우 발생
    - 해결방법 : 캐시 크기 증가
- 충돌 미스(Conflict Miss)
    - 직접 매핑 또는 집합 연관 매핑에서, 서로 다른 블록이 같은 캐시 라인/집합에 배치되면서 충돌
    - 해결방법 : 연관도(associativity) 증가

### 캐시 매핑 방식

---

> CPU가 특정 메모리 주소를 캐시에 어떻게 저장할지 결정하는 방법
> 
- 직접 매핑(Direct Mapping)
    - 각 메모리 블록이 캐시의 **특정 라인 하나**에만 저장됨
    - 구조 단순, 접근 빠름
    - 단점: 서로 다른 블록이 같은 라인에 매핑될 경우 **충돌 미스** 잦음
- 연관 매핑(Fully Associative Mapping)
    - 메모리 블록이 캐시의 **모든 라인**에 저장 가능
    - 충돌 거의 없음
    - 단점: 모든 태그를 비교해야 해서 **하드웨어 복잡, 속도↓**
- 집합 연관 매핑(Set-Associative Mapping)
    - 캐시를 여러 집합(Set)으로 나누고, 메모리 블록은 특정 집합에 배치
    - 집합 내에서는 자유롭게 저장 가능 (예: 4-way → 집합당 4라인)
    - 직접/연관 매핑의 절충안, 현대 CPU 대부분이 사용

### 캐시 교체/쓰기 정책

---

**캐시 교체 정책(Cache Replacement Policy)**

> 캐시가 가득 찼을 때 어떤 블록을 버리고 새 데이터를 넣을지 결정
> 
- LRU(Least Recently Used)
- FIFO(First-In First-Out)
- Random

**캐시 쓰기 정책**

> CPU가 캐시에 데이터를 쓸 때, 메모리와의 동기화 방법
> 
- Write-through
    - 캐시에 쓰면서 동시에 메모리에도 즉시 반영
    - 장점: 메모리와 항상 동기화되어 **일관성 보장**
    - 단점: 매번 메모리에 접근해야 하므로 **속도↓, 버스 트래픽↑**
- Write-back
    - 캐시에만 먼저 쓰고, 해당 블록이 교체될 때 메모리에 반영
    - 장점: 메모리 접근 횟수 줄어 **성능↑**
    - 단점: 캐시와 메모리 내용이 다를 수 있어 **동기화 관리 복잡** (Dirty bit 필요)

### 캐시 메모리 계층 구조

---

- L1 캐시 : CPU 코어 내부, 가장 빠르지만 용량 작음 (수십 KB)
- L2 캐시 : CPU와 메모리 사이, L1보다 크고 조금 느림 (수백 KB~수 MB)
- L3 캐시 : 멀티코어 CPU에서 공유, L2보다 크고 느림 (수 MB~수십 MB)

## 관련 면접 질문

- 캐시 매핑 방식에는 어떤 것이 있나요?
    - **직접 매핑 (Direct Mapping)**
    - **연관 매핑 (Fully Associative Mapping)**
    - **집합 연관 매핑 (Set-Associative Mapping)**
    
    > 캐시 매핑 방식에는 **직접 매핑, 연관 매핑, 집합 연관 매핑**이 있으며, 보통은 집합 연관 매핑이 가장 많이 쓰입니다.
    > 
- Write-through와 Write-back의 차이를 설명해보세요.
    
    > Write-through: 항상 메모리에 기록 → 안정적이지만 느림
    Write-back: 나중에 메모리에 기록 → 빠르지만 복잡
    >